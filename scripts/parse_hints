def configure_environment():
    """Dynamically set up sys.path to include the project root."""
    import sys
    import os

    # Dynamically determine the project root and add it to sys.path
    project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
    scripts_path = os.path.join(project_root, "scripts")

    # Remove conflicting paths
    if scripts_path in sys.path:
        sys.path.remove(scripts_path)

    # Add project root to sys.path
    if project_root not in sys.path:
        sys.path.insert(0, project_root)

# Call environment setup before importing anything from src
configure_environment()
#!/usr/bin/env python3
"""
This script sets up the environment, parses hints from a hints.txt file,
and encodes them into a 12-dimensional feature vector per hint (6 presence flags
and 6 corresponding numeric values). Additionally, if the parsed hints count is 48,
a default "no hint" row is added so that the final output has shape (49, 12).
The resulting features are saved as Parquet and compressed NPZ files.
"""

import os
import pandas as pd
import argparse
from src.utils.logger import setup_logger
from src.utils.config_manager import load_config
import logging
import numpy as np  # For saving as npz

def configure_environment():
    """Dynamically set up sys.path to include the project root."""
    import sys
    import os
    project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
    scripts_path = os.path.join(project_root, "scripts")
    # Remove conflicting paths
    if scripts_path in sys.path:
        sys.path.remove(scripts_path)
    # Add project root to sys.path
    if project_root not in sys.path:
        sys.path.insert(0, project_root)

# Call environment setup before importing anything from src
configure_environment()

# Define the known hints with unique integer assignments for 6 known hints.
HINT_MAPPING = {
    "hashjoin":       1,
    "indexonlyscan":  2,
    "indexscan":      3,
    "mergejoin":      4,
    "nestloop":       5,
    "seqscan":        6
}

ALL_HINTS = list(HINT_MAPPING.keys())

def encode_hint_expanded(hint_str):
    """
    Returns a 12-dimensional feature vector for a hint string.
    For each known hint in ALL_HINTS, output:
      - presence_<hint>: 1.0 if the hint is present, else 0.0
      - value_<hint>: the numeric ID if the hint is present, else 0.0
    With 6 known hints, this produces 6 + 6 = 12 features.
    """
    hints_present = [hint.strip().lower() for hint in hint_str.split(",") if hint.strip()]
    # Only consider known hints
    known = [hint for hint in hints_present if hint in ALL_HINTS]
    presence_list = []
    value_list = []
    for hint in ALL_HINTS:
        if hint in known:
            presence_list.append(1.0)
            value_list.append(float(HINT_MAPPING[hint]))
        else:
            presence_list.append(0.0)
            value_list.append(0.0)
    return presence_list + value_list

def build_column_names():
    """
    Build a list of column names corresponding to the expanded features:
    For each known hint, we produce 'presence_<hint>' and 'value_<hint>'.
    With 6 hints, this yields 12 column names.
    """
    presence_cols = [f"presence_{h}" for h in ALL_HINTS]
    value_cols = [f"value_{h}" for h in ALL_HINTS]
    return presence_cols + value_cols

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--config", type=str, default="config/default_config.yaml")
    args = parser.parse_args()

    # Load configuration and set up logger
    config = load_config(args.config)
    logger = setup_logger(__name__,
                          config["logging"]["log_file"],
                          level=getattr(logging, config["logging"]["log_level"]))

    # Where to find hints.txt and where to store processed features
    hint_path = config["database"]["hint_path"]
    processed_path = config["paths"]["processed_features"]
    os.makedirs(processed_path, exist_ok=True)

    hints_file = os.path.join(hint_path, "hints.txt")
    if not os.path.exists(hints_file):
        logger.warning("No hints.txt found.")
        exit(0)

    # Parse each line in hints.txt into a 12-dimensional feature vector.
    hints_data = []
    with open(hints_file, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if line:
                vec = encode_hint_expanded(line)
                hints_data.append(vec)

    if not hints_data:
        logger.warning("No hints parsed from hints.txt. Exiting.")
        exit(0)

    # Ensure the final matrix has 49 rows.
    # If we only parsed 48 hints, add an extra row representing "no hint" (all zeros).
    if len(hints_data) == 48:
        no_hint_vec = [0.0] * 12
        hints_data.append(no_hint_vec)
        logger.info("Added 'no hint' row to yield 49 rows.")

    column_names = build_column_names()
    df_hints = pd.DataFrame(hints_data, columns=column_names)

    # Save as Parquet
    parquet_output_file = os.path.join(processed_path, "Y_expanded.parquet")
    df_hints.to_parquet(parquet_output_file, index=False)
    logger.info(f"Saved expanded hint features to {parquet_output_file}")

    # Save as NPZ
    npz_output_file = os.path.join(processed_path, "Y_expanded.npz")
    np.savez_compressed(npz_output_file,
                        Y=df_hints.values,
                        columns=np.array(column_names, dtype='object'))
    logger.info(f"Saved expanded hint features to {npz_output_file}")
